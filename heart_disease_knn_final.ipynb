{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SriDivyaKrovvidi/heart-disease-prediction-knn/blob/main/heart_disease_prediction_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GeHPHkA-Lye"
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPCxewdr_LiI"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mm1uqPZuCWe5"
   },
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "MWV0CdFiESD_",
    "outputId": "aec78471-9b38-4e38-c894-56cb3bab3925"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('heart_disease_prediction.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj1C0MM0ExdE"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we will explore the dataset using summary statistics and visualizations.  \n",
    "We aim to identify data distributions, relationships, and potential data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I_ANk0OE6Aw",
    "outputId": "a8726869-c4bf-401f-ac6f-e6a7dcf5758d"
   },
   "outputs": [],
   "source": [
    "# View basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "U-RAYC1TFA7t",
    "outputId": "6e0c69b0-1b95-4de3-ec56-e097350f346c"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHy4X8CtFJxJ"
   },
   "source": [
    "### Dataset Overview\n",
    "\n",
    "Letâ€™s examine the basic structure of the dataset, check for missing values, and understand the feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "NdsQc1sgFMfo",
    "outputId": "d7290f4c-fb9e-4a94-ef5a-1d1bf332cff7"
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()\n",
    "\n",
    "# Check class distribution\n",
    "df['HeartDisease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3FuYqULHA4H"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before training the K-Nearest Neighbors model, we need to:\n",
    "- Encode categorical features into numerical values\n",
    "- Scale numerical features (since KNN is distance-based)\n",
    "- Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "lNPA1_qnHCCe",
    "outputId": "0e7e6138-10c1-40d6-88c7-a94960b2b291"
   },
   "outputs": [],
   "source": [
    "# categorical column names list\n",
    "categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvLKoJM_JEIk"
   },
   "source": [
    "### Feature Scaling\n",
    "\n",
    "KNN is a distance-based algorithm, so we scale all features using StandardScaler.  \n",
    "This ensures that each feature contributes equally to distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTnpdFI_JFdb",
    "outputId": "82e3d33c-3176-42a3-f93d-65b62d9a775a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Separate features and target variable\n",
    "X = df_encoded.drop('HeartDisease', axis=1)\n",
    "y = df_encoded['HeartDisease']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training data and transform\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Check the result\n",
    "print(\"Before scaling (first 5 rows):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nAfter scaling (first 5 rows):\")\n",
    "print(X_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4ZHlO9EJgUH"
   },
   "source": [
    "###Train/Test Split\n",
    "\n",
    "We split the dataset into training and test sets using an 80/20 ratio.  \n",
    "This helps us evaluate how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8RKHxBFJNyp",
    "outputId": "1049ad6c-03ba-46f1-880e-4bb089ccffcf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test sets (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Check the shape of each split\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxeVrPUeJqur"
   },
   "source": [
    "### Initial Model Training (k=5)\n",
    "\n",
    "We train a K-Nearest Neighbors (KNN) classifier using \"k=5\".  \n",
    "This model will learn from the training data and then predict on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAudw883J16d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN model with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATRcmD2GKAjO"
   },
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We evaluate the model using accuracy, confusion matrix, and a classification report.  \n",
    "These metrics help us understand how well the model is predicting both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FivNYk7KDRh",
    "outputId": "290c3d34-0141-471d-eefd-afc3caaaffa5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X89a2Y1QKgOE"
   },
   "source": [
    "### Hyperparameter Tuning: Finding the Best `k`\n",
    "\n",
    "We loop through different `k` values (from 1 to 20) and track the prediction error.  \n",
    "The goal is to find the value of `k` that minimizes classification error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "EwQx1c65Kirv",
    "outputId": "415f2c35-9ff5-43d6-b651-77f7136f6311"
   },
   "outputs": [],
   "source": [
    "error_rates = []\n",
    "\n",
    "# Try k values from 1 to 20\n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_k = knn.predict(X_test)\n",
    "    error = np.mean(pred_k != y_test)\n",
    "    error_rates.append(error)\n",
    "\n",
    "# Plot error rate vs. k\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 21), error_rates, marker='o')\n",
    "plt.title('Error Rate vs K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Mean Error Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu1nYDpBKtBk"
   },
   "source": [
    "Final Model with Optimal `k`\n",
    "\n",
    "We retrain the KNN model using the `k` value that gave us the lowest error rate.  \n",
    "This should give us the best performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QcuevUdKw2I",
    "outputId": "3c25c18c-1b8a-42c2-99f9-48f41cbbfb1d"
   },
   "outputs": [],
   "source": [
    "# Replace this with your actual best k (e.g., 7 or 9, etc.)\n",
    "BEST_K = 7  # example only\n",
    "# Train final model\n",
    "knn_final = KNeighborsClassifier(n_neighbors=BEST_K)\n",
    "knn_final.fit(X_train, y_train)\n",
    "y_final_pred = knn_final.predict(X_test)\n",
    "# Evaluate\n",
    "print(\"Final Accuracy (k={}):\".format(BEST_K), accuracy_score(y_test, y_final_pred))\n",
    "print(\"\\nFinal Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_final_pred))\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_final_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "xWIxrCsOK-6A",
    "outputId": "2ad729b5-c36f-4851-ea83-268f3350d9f7"
   },
   "outputs": [],
   "source": [
    "# Re-calculate and plot error rates for k = 1 to 20\n",
    "error_rates = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_k = knn.predict(X_test)\n",
    "    error = np.mean(pred_k != y_test)\n",
    "    error_rates.append(error)\n",
    "# Plot the error rate for each k\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 21), error_rates, marker='o')\n",
    "plt.title('Error Rate vs K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Mean Error Rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-iacJv-LOSi"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we built a machine learning model to predict the presence of heart disease using patient health records.  \n",
    "We used the K-Nearest Neighbors (KNN) algorithm, which classifies a data point based on the majority vote of its neighbors.\n",
    "\n",
    "After cleaning the data, encoding categorical features, scaling numerical features, and splitting the dataset, we trained and evaluated a KNN model.\n",
    "\n",
    "We tuned the `k` hyperparameter to find the optimal value, and observed how model accuracy and error rate changed with different `k` values.\n",
    "\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- KNN is a simple yet effective model for classification problems.\n",
    "- Feature scaling is **critical** for distance-based algorithms like KNN.\n",
    "- The dataset was relatively well-balanced, so accuracy was a useful metric.\n",
    "- Hyperparameter tuning (like choosing the best `k`) can significantly improve model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## What I Learned\n",
    "\n",
    "- How to preprocess data for machine learning\n",
    "- How to encode categorical variables using one-hot encoding\n",
    "- Why and how to scale numerical features\n",
    "- How to train and evaluate a KNN model using scikit-learn\n",
    "- How to interpret a confusion matrix and classification report\n",
    "- How to tune a hyperparameter (`k`) using error rate plots\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To further improve or expand this project, I could:\n",
    "- Try other classification algorithms (e.g., Logistic Regression, Random Forest)\n",
    "- Use cross-validation instead of a single train-test split\n",
    "- Deploy the model using a simple web app (like Streamlit or Flask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp5UpejrLUs8"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZOfrk4zw8mQXylAiMIHUV",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
